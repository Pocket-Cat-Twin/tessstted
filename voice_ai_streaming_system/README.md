# Voice-to-AI Streaming System

Enterprise-grade real-time voice processing system with invisible overlay for AI-powered responses. 

## Features

### Core Functionality
- **Dual Audio Capture**: Separate recording from microphone (user) and system output (interlocutor)
- **Hotkey System**: Global hotkeys for start/stop recording with configurable key combinations
- **Real-time STT**: Speech-to-text conversion with multiple provider support (Google, Azure, Whisper)
- **AI Integration**: Streaming responses from OpenAI GPT-4 and Anthropic Claude
- **Invisible Overlay**: Transparent window display with always-on-top functionality
- **Voice Activity Detection**: Smart detection of speech vs. silence

### Architecture Highlights
- **Event-driven**: Decoupled components communicating via event bus
- **Multi-threaded**: Separate threads for audio, STT, AI, and UI operations  
- **State Management**: Centralized state tracking with real-time updates
- **Configuration**: Comprehensive settings with JSON persistence
- **Logging**: Multi-level logging with component-specific outputs
- **Performance Monitoring**: Real-time CPU, memory, and latency tracking

## Project Structure

```
voice_ai_streaming_system/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ todo.md                      # Development roadmap
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ default_config.json      # Default configuration
â”‚   â”œâ”€â”€ settings.py              # Configuration management
â”‚   â””â”€â”€ user_config.json         # User customizations (created at runtime)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                  # Application entry point
â”‚   â”œâ”€â”€ audio/                   # Audio processing modules
â”‚   â”‚   â”œâ”€â”€ capture_service.py   # Dual audio capture (mic + system)
â”‚   â”‚   â”œâ”€â”€ buffer_manager.py    # Audio buffer management
â”‚   â”‚   â””â”€â”€ vad_detector.py      # Voice activity detection
â”‚   â”œâ”€â”€ hotkeys/                 # Global hotkey system
â”‚   â”‚   â””â”€â”€ hotkey_manager.py    # Hotkey registration and handling
â”‚   â”œâ”€â”€ stt/                     # Speech-to-text services
â”‚   â”‚   â”œâ”€â”€ base_stt.py          # STT service interface
â”‚   â”‚   â”œâ”€â”€ google_stt.py        # Google Cloud Speech
â”‚   â”‚   â”œâ”€â”€ azure_stt.py         # Azure Speech Services
â”‚   â”‚   â””â”€â”€ whisper_stt.py       # Local Whisper processing
â”‚   â”œâ”€â”€ ai/                      # AI response services
â”‚   â”‚   â”œâ”€â”€ base_ai.py           # AI service interface
â”‚   â”‚   â”œâ”€â”€ openai_client.py     # OpenAI GPT integration
â”‚   â”‚   â””â”€â”€ anthropic_client.py  # Anthropic Claude integration
â”‚   â”œâ”€â”€ overlay/                 # Invisible overlay system
â”‚   â”‚   â”œâ”€â”€ invisible_window.py  # Windows overlay implementation
â”‚   â”‚   â””â”€â”€ overlay_manager.py   # Overlay control logic
â”‚   â”œâ”€â”€ ui/                      # User interface components
â”‚   â”‚   â”œâ”€â”€ settings_window.py   # Configuration UI
â”‚   â”‚   â””â”€â”€ system_tray.py       # System tray integration
â”‚   â”œâ”€â”€ core/                    # Core system components
â”‚   â”‚   â”œâ”€â”€ event_bus.py         # Inter-component communication
â”‚   â”‚   â”œâ”€â”€ state_manager.py     # Global state management
â”‚   â”‚   â””â”€â”€ thread_coordinator.py # Threading management
â”‚   â””â”€â”€ utils/                   # Utility modules
â”‚       â””â”€â”€ logger.py            # Logging framework
â”œâ”€â”€ tests/                       # Unit and integration tests
â””â”€â”€ data/
    â”œâ”€â”€ logs/                    # Application logs
    â””â”€â”€ recordings/              # Temporary audio storage
```

## Installation

### Prerequisites
- Python 3.8+
- Windows 10/11 (for overlay functionality)
- Audio input/output devices

### Setup
1. Clone or extract the project
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Configure API keys in `config/user_config.json`
4. Run the application:
   ```bash
   python src/main.py
   ```

## Configuration

### Audio Settings
- **Sample Rate**: 16kHz (recommended) or higher
- **Buffer Size**: 1024 samples for optimal latency
- **Device Selection**: Automatic detection with manual override
- **VAD**: Voice Activity Detection with WebRTC or energy-based algorithms

### Hotkey Configuration
Default hotkeys (customizable):
- `Ctrl+Shift+F1`: Start recording
- `Ctrl+Shift+F2`: Stop recording and process
- `Ctrl+Shift+F3`: Toggle overlay visibility
- `Ctrl+Shift+F4`: Toggle settings window
- `Ctrl+Shift+Esc`: Emergency stop

### API Configuration
Required API keys:
- **Google Cloud Speech**: Service account credentials
- **Azure Speech**: Subscription key and region
- **OpenAI**: API key for GPT models
- **Anthropic**: API key for Claude models

## Usage Workflow

1. **Start Application**: Launch with `python src/main.py`
2. **Configure Settings**: Set audio devices and API credentials
3. **Begin Recording**: Press `Ctrl+Shift+F1` to start capturing interlocutor audio
4. **Process Voice**: Press `Ctrl+Shift+F2` to stop recording and send to AI
5. **View Response**: AI response appears in invisible overlay
6. **Repeat**: Continue conversation cycle

## Performance Targets

- **Audio Latency**: < 50ms buffer latency
- **STT Processing**: < 500ms for short phrases  
- **AI Response**: < 2000ms for first token
- **Resource Usage**: < 20% CPU, < 300MB RAM
- **Overlay Rendering**: < 16ms for smooth display

## Development Status

### Completed Components âœ…
- [x] Project structure and configuration system
- [x] Comprehensive logging framework  
- [x] Event-driven architecture with event bus
- [x] Global state management system
- [x] Thread coordination and management
- [x] Dual audio capture (microphone + system output)
- [x] Audio buffer management with circular buffers
- [x] Voice activity detection (WebRTC + energy-based)
- [x] Global hotkey system with multiple backends
- [x] Core infrastructure and base classes

### Next Development Phases ðŸš§
- [ ] STT service implementation (Google, Azure, Whisper)
- [ ] AI response services (OpenAI, Anthropic)  
- [ ] Invisible overlay system (Windows-specific)
- [ ] Settings UI and system tray integration
- [ ] End-to-end integration testing
- [ ] Performance optimization and monitoring
- [ ] Error handling and recovery mechanisms
- [ ] Packaging and distribution

## Architecture Patterns

### Event-Driven Communication
```python
# Components communicate via events
event_bus.emit(EventType.RECORDING_STARTED, "audio_capture", {
    "device": "microphone",
    "timestamp": time.time()
})
```

### State Management
```python
# Centralized state updates
state_manager.update_recording_state(
    is_recording=True,
    start_time=time.time()
)
```

### Thread Coordination
```python
# Managed thread lifecycle
thread_coordinator.start_thread(
    "audio_capture",
    audio_capture_function,
    ThreadType.AUDIO_CAPTURE
)
```

### Configuration Management
```python
# Type-safe configuration
settings = config_manager.get_settings()
audio_config = settings.audio
```

## Security & Privacy

- **No persistent audio storage**: Audio deleted after processing
- **API key encryption**: Secure credential storage using Windows DPAPI
- **Local processing**: Minimize data transmission to external services
- **User consent**: Clear disclosure of data usage and processing

## Contributing

This is an enterprise-grade implementation focusing on:
- **Code Quality**: Type hints, comprehensive error handling
- **Performance**: Optimized for real-time processing
- **Maintainability**: Clear separation of concerns
- **Testability**: Modular design with dependency injection
- **Documentation**: Comprehensive inline and external documentation

## License

Internal development project - see organization licensing terms.

## Support

For technical issues or feature requests, refer to the development team or internal documentation systems.